


Also add evaluating harmful/biased responses in all evals.


Evaluate latest LLMs.


Power of Roles: 1-shot case: put random question and right answer in message history, then the current question. This is a way for 1-shot prompting using the power of roles.


Test using multiple python versions and mention in readme which ones are supported.
Ask AI to suggest a better name.
Follow all standards for python packages.
Ask copilot to review.

Share on LinkedIn & X - both eval method and results.
	- Mention that this is old problem found years ago but not solved.
	- Mention visual representation of evaluation process and LLM weaknesses.

Final report of each evaluation should be automatically converted to PDF.
